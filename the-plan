Data

There are several sources of data that we can use. The James Watson genome is used as the standard benchmark for various genome compression algorithms. James Watson's genome is freely available on line: http://jimwatsonsequence.cshl.edu/cgi-perl/gbrowse/jwsequence/. For the reference genome, the UCSC Genome Bioinformatics site (http://genome.ucsc.edu/index.html), contains hg19, a "finished" human reference genome as well as various annotations, SNP masked files and alignments with various other species that could be of use. Our aim is to use hg19, as well as the various annotations and references provided, to compress the James Watson genome, as well as test our algorithm on some other complete genomes. Complete Genomics (http://www.completegenomics.com/) provides several full sequenced genomes with high coverage that we could use. The data from the UCSC site is provided in the standard 2-bit format, the smallest possible format with no kind of encoding where every base is represented by 2 bits. However, most of the other data, including the James Watson sequence and the data from Complete Genomics needs to be converted into this format. We aim to convert to the 2-bit format because it appears by far the easiest to work with. The main other piece of data we would probably require is the SNP database, the use of which we've seen in our literature survey. This is also available in the UCSC site.

Method

There are a couple of methods we're planning to explore:

* Compression of the genome as a stand-alone sequence. How much can the genome be compressed without using any reference? The repetitive properties of DNA - SNPs, tandem repeats, interspersed repeats and the possible differences - copy number variations and such variations can be effectively used to compress the literal text sequence to a large extent without any reference.
* Compression against a reference. The human reference genome contains genetic material sampled from a number of individuals. Several estimates show that the similarity between the DNA sequences of two individuals is around 99.5%, which means that only around 0.5% of the DNA sequence varies between two individuals. It should be possible to achieve a high degree of compression by storing only the difference of the specific DNA sequence against the reference genome. We also know that many of these differences are also described as small, specific variations in known sequences (SNPs, inversions, for instance). Encoding these differences effectively would lead to a high degree of compression as well.

In the end, our method would most likely take parts from both these approaches as required. Identifying repetitive patterns and which specific portions of the DNA tend to differ would be an important step towards the goal. Existing approaches (DNA Zip project) have been able to compress James Watson's DNA to around 4MB (roughly 0.5% of the 2-bit representation of a 3 billion base-pair genome). This is probably somewhere around the lower limit of the compression that can be achieved.
